{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 28 * 28\n",
    "intermediate_dim = 64\n",
    "latent_dim = 2\n",
    "\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 17s 5ms/step - loss: 185.4042 - val_loss: 167.2392\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 164.9700 - val_loss: 163.1880\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 161.9028 - val_loss: 160.8439\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 159.8208 - val_loss: 159.2599\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 158.3077 - val_loss: 157.9344\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 157.0813 - val_loss: 156.7515\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 156.0982 - val_loss: 156.2495\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 155.2308 - val_loss: 155.3689\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 154.5206 - val_loss: 154.7143\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 153.8668 - val_loss: 153.9973\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 153.2925 - val_loss: 153.6776\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 152.7662 - val_loss: 152.9448\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 152.3124 - val_loss: 152.8302\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 151.8771 - val_loss: 152.2441\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 151.4931 - val_loss: 152.0295\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 151.1624 - val_loss: 152.0197\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 150.8430 - val_loss: 151.6040\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 150.5306 - val_loss: 151.4704\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 150.2637 - val_loss: 150.8440\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 149.9200 - val_loss: 150.6537\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 149.6362 - val_loss: 150.1822\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 149.3627 - val_loss: 150.0176\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 149.1174 - val_loss: 149.7476\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 148.8674 - val_loss: 149.7928\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 148.6515 - val_loss: 149.4792\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 148.4525 - val_loss: 149.3573\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 148.2588 - val_loss: 149.1835\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 148.1059 - val_loss: 149.0532\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 147.8947 - val_loss: 148.7472\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 147.7504 - val_loss: 148.6150\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 147.6145 - val_loss: 148.8311\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 147.4556 - val_loss: 148.4936\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 147.3148 - val_loss: 148.3667\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 147.1574 - val_loss: 148.3343\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 147.0212 - val_loss: 148.1723\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 146.9348 - val_loss: 148.2288\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 146.7677 - val_loss: 148.1139\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 146.6794 - val_loss: 147.9228\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 146.5530 - val_loss: 147.7303\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 146.4499 - val_loss: 147.7450\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 146.3177 - val_loss: 147.5362\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 146.2374 - val_loss: 147.7011\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 146.1363 - val_loss: 147.7034\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 146.0172 - val_loss: 147.5612\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 145.9402 - val_loss: 147.3285\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 145.8591 - val_loss: 147.3911\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 145.7540 - val_loss: 147.3984\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 145.6615 - val_loss: 147.1880\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 145.5858 - val_loss: 147.5190\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 145.5065 - val_loss: 146.9737\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 145.4052 - val_loss: 147.1959\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 145.3585 - val_loss: 146.8663\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 145.2814 - val_loss: 147.0838\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 145.2173 - val_loss: 146.8593\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 145.0988 - val_loss: 146.6472\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 145.0575 - val_loss: 146.8869\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 144.9774 - val_loss: 147.6112\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 144.9291 - val_loss: 146.5087\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 144.8501 - val_loss: 146.3667\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 144.7638 - val_loss: 146.6065\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 144.7108 - val_loss: 146.4307\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 144.6694 - val_loss: 146.8599\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 144.5964 - val_loss: 146.4838\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 144.5343 - val_loss: 146.5507\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 144.4789 - val_loss: 146.2541\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 144.3988 - val_loss: 146.4535\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 144.4029 - val_loss: 145.9018\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 144.3262 - val_loss: 146.5264\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 144.2938 - val_loss: 146.0801\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 144.2251 - val_loss: 146.9018\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 144.2130 - val_loss: 146.4012\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 144.1284 - val_loss: 146.5185\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 144.0512 - val_loss: 146.2425\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 144.0271 - val_loss: 146.2841\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.9676 - val_loss: 146.0092\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.9107 - val_loss: 146.1439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.8766 - val_loss: 146.0573\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.8277 - val_loss: 145.8434\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.8062 - val_loss: 146.1196\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.7682 - val_loss: 145.9338\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.6964 - val_loss: 146.1942\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.6539 - val_loss: 145.9367\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.6180 - val_loss: 146.1977\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.5906 - val_loss: 145.9328\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.5368 - val_loss: 145.6210\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.5126 - val_loss: 145.7448\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.4891 - val_loss: 145.7664\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.4294 - val_loss: 145.7004\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.4104 - val_loss: 145.5704\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.3575 - val_loss: 145.8337\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.3344 - val_loss: 145.6454\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.2853 - val_loss: 145.4873\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 143.2358 - val_loss: 145.7323\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.2546 - val_loss: 145.4566\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.1827 - val_loss: 145.4570\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.1480 - val_loss: 145.5060\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.1150 - val_loss: 145.6353\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 143.0977 - val_loss: 145.4338\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.0340 - val_loss: 145.3376\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 143.0478 - val_loss: 145.4782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdc5d6864c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3136093f90d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "x_test_encoded = encoder.predict(x_test)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# We will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "datapath = \"../../../deeplearning/TensorFlow2.0_ResNet/dataset/\"\n",
    "# datapath = \"../../../deeplearning/covidDataset/\"\n",
    "print(os.path.exists(datapath))\n",
    "image_dims = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1488 images belonging to 2 classes.\n",
      "Found 495 images belonging to 2 classes.\n",
      "Found 498 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists(datapath)==True):\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    train_generator = train_datagen.flow_from_directory(os.path.join(datapath, \"train\"),\n",
    "                                                 target_size = image_dims,\n",
    "                                                batch_size = 16,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                color_mode = 'rgb')\n",
    "    test_generator = test_datagen.flow_from_directory(os.path.join(datapath, \"test\"), \n",
    "                                                                 target_size = image_dims,\n",
    "                                                                  batch_size = 16,\n",
    "                                                                 class_mode = 'categorical', \n",
    "                                                                 color_mode = 'rgb')\n",
    "    validation_generator = validation_datagen.flow_from_directory(os.path.join(datapath, \"valid\"), \n",
    "                                                         target_size = image_dims,\n",
    "                                                          batch_size = 16,\n",
    "                                                         class_mode = 'categorical', \n",
    "                                                         color_mode = 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator, test_generator, validation_generator = get_imagedatagenerator(datapath)\n",
    "# x_train, y_train = next(train_generator)\n",
    "# x_test, y_test = next(test_generator)\n",
    "# x_valid, y_valid = next(validation_generator)\n",
    "# n = 6\n",
    "# plt.figure(figsize=(20, 4))\n",
    "# for i in range(n):\n",
    "#     ax = plt.subplot(1, n, i+1)\n",
    "#     ax.set(xlabel=\"label - {}\".format(y_train[i]))\n",
    "#     img = x_train[i]\n",
    "#     ax.imshow(img, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain , ytrain = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(ytrain[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = tf.keras.applications.VGG19(weights='imagenet',\n",
    "                                      include_top=False,\n",
    "                                        input_shape=(224, 224, 3))\n",
    "vgg_model.trainable=False \n",
    "\n",
    "x = vgg_model.layers[-1].output\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(500, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "vgg_output = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "vgg = tf.keras.models.Model(vgg_model.input, vgg_output)\n",
    "vgg._name='vgg19'\n",
    "# vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 114s 1s/step - loss: 1.7932 - binary_accuracy: 0.5659\n"
     ]
    }
   ],
   "source": [
    "history = vgg.fit(train_generator,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = vgg.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense169_model = tf.keras.applications.DenseNet169(weights='imagenet',\n",
    "                                      include_top=False,\n",
    "                                        input_shape=(224, 224, 3)\n",
    "                                      )\n",
    "# dense169_model.summary()\n",
    "dense169_model.trainable=False \n",
    "\n",
    "y = dense169_model.layers[-1].output\n",
    "y = tf.keras.layers.Flatten()(y)\n",
    "y = tf.keras.layers.Dropout(0.5)(y)\n",
    "y = tf.keras.layers.Dense(1000, activation='relu')(y)\n",
    "y = tf.keras.layers.Dropout(0.5)(y)\n",
    "densenet_1_output = tf.keras.layers.Dense(2, activation='softmax')(y)\n",
    "\n",
    "densenet_1 = tf.keras.models.Model(dense169_model.input, densenet_1_output)\n",
    "densenet_1._name='densenet_1'\n",
    "# densenet_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 116s 1s/step - loss: 5.0573 - binary_accuracy: 0.7809\n"
     ]
    }
   ],
   "source": [
    "densenet_1_history = densenet_1.fit(train_generator,\n",
    "                    epochs=1,\n",
    "                    batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = densenet_1.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense169_model2 = tf.keras.applications.DenseNet169(weights='imagenet',\n",
    "                                      include_top=False,\n",
    "                                        input_shape=(224, 224, 3)\n",
    "                                      )\n",
    "# dense169_model.summary()\n",
    "dense169_model2.trainable=False \n",
    "# since the model is already loaded we load in again\n",
    "z = dense169_model2.layers[-1].output\n",
    "z = tf.keras.layers.Flatten()(z)\n",
    "z = tf.keras.layers.Dropout(0.5)(z)\n",
    "z = tf.keras.layers.Dense(1000, activation='relu')(z)\n",
    "z = tf.keras.layers.Dropout(0.5)(z)\n",
    "z = tf.keras.layers.Dense(500, activation='relu')(z)\n",
    "z = tf.keras.layers.Dropout(0.5)(z)\n",
    "z = tf.keras.layers.Dense(200, activation='relu')(z)\n",
    "z = tf.keras.layers.Dropout(0.5)(z)\n",
    "densenet_2_output = tf.keras.layers.Dense(2, activation='softmax')(z)\n",
    "\n",
    "densenet_2 = tf.keras.models.Model(dense169_model2.input, densenet_2_output)\n",
    "densenet_2._name='densenet_2'\n",
    "# densenet_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 105s 1s/step - loss: 7.7802 - binary_accuracy: 0.6156\n"
     ]
    }
   ],
   "source": [
    "densenet_2_history = densenet_2.fit(train_generator,\n",
    "                    epochs=1,\n",
    "                    batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.trainable = False\n",
    "densenet_1.trainable = False\n",
    "densenet_2.trainable = False\n",
    "models = [vgg, densenet_1, densenet_2]\n",
    "# to avoid conflicts with naming\n",
    "for layer in models[0].layers:\n",
    "    layer._name = layer.name + str('_0')\n",
    "for layer in models[1].layers:\n",
    "    layer._name = layer.name + str('_1')\n",
    "for layer in models[2].layers:\n",
    "    layer._name = layer.name + str('_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = tf.keras.layers.Average()([vgg.output, densenet_1.output, densenet_2.output])\n",
    "dense = tf.keras.layers.Dense(1, activation='sigmoid')(average)\n",
    "\n",
    "ensemble = tf.keras.Model([vgg.input, densenet_1.input, densenet_2.input], dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataGenerator(tf.keras.utils.Sequence):\n",
    "#     'Generates data for Keras'\n",
    "#     def __init__(self, paths, labels, batch_size=16, dim=(224, 224), n_channels=3,\n",
    "#                  n_classes=2, shuffle=True):\n",
    "#         'Initialization'\n",
    "#         self.dim = dim\n",
    "#         self.batch_size = batch_size\n",
    "#         self.labels = labels\n",
    "#         self.paths = paths\n",
    "#         self.n_channels = n_channels\n",
    "#         self.n_classes = n_classes\n",
    "#         self.shuffle = shuffle\n",
    "#         self.on_epoch_end()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return int(len(self.paths) / self.batch_size)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         # Generate indexes of the batch\n",
    "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "#         # Find list of IDs\n",
    "#         list_paths = [self.paths[k] for k in indexes]\n",
    "#         y = [self.labels[k] for k in indexes]\n",
    "#         y = np.array(y)\n",
    "\n",
    "#         # Generate data\n",
    "#         X = self.__data_generation(list_paths)\n",
    "\n",
    "#         return [X,X,X],y\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         self.indexes = np.arange(len(self.paths))\n",
    "#         if self.shuffle == True:\n",
    "#             np.random.shuffle(self.indexes)\n",
    "\n",
    "#     def __data_generation(self, list_paths):\n",
    "#         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "#         # Initialization\n",
    "#         X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "#         # Generate data\n",
    "#         for i, path in enumerate(list_paths):           \n",
    "#             image = tf.keras.preprocessing.image.load_img(path)\n",
    "#             image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "#             image_arr = tf.image.resize(image_arr,(self.dim[0], self.dim[1])).numpy()\n",
    "#             X[i,] = image_arr/255\n",
    "#         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "\n",
    "# x_train = list(pathlib.Path(os.path.join(datapath, \"train\")).glob(\"*/*\"))\n",
    "# print(len(x_train))\n",
    "# y_train = [pathlib.Path(path).parent.name for path in x_train]\n",
    "# print(len(y_train))\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# le.fit(y_train)\n",
    "# labels = le.transform(y_train)\n",
    "# print(y_train[1], \" \", labels[1])\n",
    "# print(y_train[1000], \" \", labels[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = DataGenerator(x_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = train_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x))\n",
    "\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the below approach of multiple image inputs to a ```model.fit()``` using ```ImageDataGenerator```was used from [github issues](https://github.com/keras-team/keras/issues/8130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_generator_multiple(generator,dir1, batch_size, img_height,img_width):\n",
    "    genX1 = generator.flow_from_directory(dir1,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          color_mode='rgb',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    \n",
    "    genX2 = generator.flow_from_directory(dir1,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          color_mode = 'rgb',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    genX3 = generator.flow_from_directory(dir1,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          color_mode = 'rgb',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            X3i = genX3.next()\n",
    "            yield [X1i[0], X2i[0], X3i[0]], X3i[1]  #Yield both images and their mutual label\n",
    "            \n",
    "input_gen = ImageDataGenerator(rescale=1.0/255)\n",
    "input_generator = generate_generator_multiple(generator=input_gen,\n",
    "                                             dir1=os.path.join(datapath, \"train\"),\n",
    "                                             batch_size=16,\n",
    "                                              img_height=224,\n",
    "                                              img_width=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(input_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generator(samples, labels, batch_size=16):\n",
    "#     \"\"\"\n",
    "#     Yields the next training batch.\n",
    "#     Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
    "#     \"\"\"\n",
    "#     num_samples = len(samples)\n",
    "#     while True: # Loop forever so the generator never terminates\n",
    "# #         shuffle(samples)\n",
    " \n",
    "#         # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             # Get the samples you'll use in this batch\n",
    "#             batch_samples = samples[offset:offset+batch_size]\n",
    "#             batch_labels = labels[offset:offset+batch_size]\n",
    "#             # Initialise X_train and y_train arrays for this batch\n",
    "#             X_train = []\n",
    "#             y_train = []\n",
    " \n",
    "#             # For each example\n",
    "#             for batch_sample in batch_samples:\n",
    "#                 # Load image (X)\n",
    "# #                 filename = './common_filepath/'+batch_sample[0]\n",
    "#                 image = tf.keras.preprocessing.image.load_img(batch_sample)\n",
    "#                 image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "#                 image_arr = tf.image.resize(image_arr,(224, 224)).numpy()\n",
    "#                 image = image_arr / 255\n",
    "#                 # Read label (y)\n",
    "# #                 y = batch_sample[1]\n",
    "#                 # Add example to arrays\n",
    "#                 X_train.append(image)\n",
    "#             for label in batch_labels:\n",
    "#                 y = label\n",
    "#                 y_train.append(y)\n",
    " \n",
    "#             # Make sure they're numpy arrays (as opposed to lists)\n",
    "#             X_train = np.array(X_train)\n",
    "#             y_train = np.array(y_train)\n",
    " \n",
    "#             # The generator-y part: yield the next training batch            \n",
    "#             yield [X_train, X_train, X_train], y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = generator(x_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = train.__next__()\n",
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 320s 3s/step - loss: 0.6939 - binary_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "ensemble_history = ensemble.fit(input_generator,\n",
    "                                epochs=1,\n",
    "                                steps_per_epoch=93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resources\n",
    "### [Using generators in Python to train machine learning models](http://www.jessicayung.com/using-generators-in-python-to-train-machine-learning-models/)\n",
    "\n",
    "### [Write your own Custom Data Generator for TensorFlow Keras](https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3)\n",
    "\n",
    "### [A detailed example of how to use data generators with Keras](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)\n",
    "\n",
    "### [Github Issue :  how to use fit_generator with multiple image inputs #8130 ](https://github.com/keras-team/keras/issues/8130)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
